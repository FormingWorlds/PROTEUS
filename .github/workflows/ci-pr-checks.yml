name: CI - Fast PR Checks

# Purpose: Fast feedback for pull requests using pre-built Docker image
# Strategy:
#   1. Use pre-compiled Docker image (ghcr.io/formingworlds/proteus:latest)
#   2. Overlay PR code changes onto the container
#   3. Smart rebuild: Only recompile changed source files (make handles this)
#   4. Run @pytest.mark.unit tests with mocked physics (fast, ~2-5 min total)
#   5. Run @pytest.mark.smoke tests with real binaries (1 timestep, low res, ~2-5 min)
#   6. Exclude placeholder tests (@pytest.mark.skip) - these are placeholders for future implementation
#
# Test Categories (see docs/test_infrastructure.md):
#   @pytest.mark.unit    -> 94 fast tests implemented (as of 2026-01-10): 53 tests for helper.py + 41 tests for logs.py; target: 130+ (target: <100ms each)
#   @pytest.mark.smoke   -> 1 smoke test implemented (as of 2026-01-06); planned target: 5–7 (target: <30s each)
#   @pytest.mark.skip    -> 9 placeholder tests not yet implemented (excluded from CI)
#
# Source of truth for counts and targets: docs/test_infrastructure.md

on:
  pull_request:
    branches:
      - main
      - dev
    types:
      - opened
      - reopened
      - synchronize
      - ready_for_review
  push:
    branches:
      - main
      - dev
      - tl/test_ecosystem_v5
      - tl/test_ecosystem_v5_fast
  workflow_dispatch:  # Allow manual triggering for testing

permissions:
  contents: write  # Allow auto-commit of ratcheted coverage thresholds
  packages: read
  actions: read  # Required to download artifact from last nightly run

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: formingworlds/proteus

jobs:
  unit-tests:
    name: Unit Tests (Mocked Physics)
    runs-on: ubuntu-latest
    container:
      image: ghcr.io/formingworlds/proteus:${{ github.ref == 'refs/heads/main' && 'latest' || 'tl-test_ecosystem_v5' }}
      credentials:
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}
      options: --user root

    steps:
      - name: Checkout PR code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Prevent threshold decreases vs main
        run: |
          git config --global --add safe.directory /__w/PROTEUS/PROTEUS
          git fetch origin main
          python - <<'PY'
          import pathlib
          import subprocess
          import tomllib

          base = "origin/main"
          current = tomllib.loads(pathlib.Path("pyproject.toml").read_text())
          base_text = subprocess.check_output(["git", "show", f"{base}:pyproject.toml"], text=True)
          base_data = tomllib.loads(base_text)

          paths = {
              "full": ["tool", "coverage", "report", "fail_under"],
              "fast": ["tool", "proteus", "coverage_fast", "fail_under"],
          }

          def get_val(data, path):
              try:
                  for key in path:
                      data = data[key]
              except KeyError:
                  return None
              return float(data)

          for label, path in paths.items():
              cur = get_val(current, path)
              base_val = get_val(base_data, path)

              if base_val is None or cur is None:
                  print(f"Skipping {label} check (missing in base or current)")
                  continue

              if cur < base_val:
                  raise SystemExit(f"{label} fail_under decreased: {cur} < {base_val}")

          print("Coverage thresholds have not decreased vs main.")
          PY

      - name: Overlay PR code onto container
        run: |
          echo "Copying PR code over container base..."
          rsync -av --exclude='.git' --exclude='SPIDER' --exclude='socrates' --exclude='petsc' --exclude='AGNI' . /opt/proteus/
          cd /opt/proteus
          pip install -e ".[develop]" --no-deps

      - name: Install CI helper tools
        run: |
          cd /opt/proteus
          pip install diff-cover

      - name: Read fast coverage threshold
        run: |
          cd /opt/proteus
          python - <<'PY' >> "$GITHUB_ENV"
          import pathlib
          import tomllib

          data = tomllib.loads(pathlib.Path("pyproject.toml").read_text())
          val = float(data["tool"]["proteus"]["coverage_fast"]["fail_under"])
          print(f"FAST_COV_FAIL_UNDER={val}")
          PY

      - name: Validate test structure
        run: |
          cd /opt/proteus
          bash tools/validate_test_structure.sh

      - name: Run unit tests with coverage
        id: unit-tests
        continue-on-error: true
        run: |
          cd /opt/proteus
          # Run unit tests, excluding placeholder tests and examples
          pytest -m "unit and not skip" \
            --ignore=tests/examples \
            --cov=src --cov-report=term-missing --cov-report=xml --cov-report=html \
            --cov-fail-under=${FAST_COV_FAIL_UNDER} \
            --durations=0 \
            --durations-min=0 | tee pytest-unit.log

      - name: Smart rebuild of physics modules
        run: |
          cd /opt/proteus
          echo "Checking if Fortran/C source files changed..."

          # SOCRATES rebuild (only if sources changed)
          if [ -d "socrates" ]; then
            cd socrates
            ./build_code 2>&1 | grep -q "Nothing to be done" || {
              echo "SOCRATES needs rebuild..."
              ./build_code
            }
            cd /opt/proteus
          fi

          # AGNI rebuild (only if Julia sources changed)
          if [ -d "AGNI" ]; then
            cd AGNI
            if git diff --name-only HEAD origin/main | grep -q '\.jl$'; then
              echo "AGNI Julia sources changed, re-instantiating packages..."
              julia -e 'using Pkg; Pkg.activate("."); Pkg.instantiate()'
            else
              echo "No AGNI changes detected, skipping rebuild"
            fi
            cd /opt/proteus
          fi

      - name: Run smoke tests (append to coverage)
        id: smoke-tests
        continue-on-error: true
        run: |
          cd /opt/proteus
          pytest -m "smoke and not skip" \
            --ignore=tests/examples \
            --cov=src --cov-append \
            --cov-report=term-missing --cov-report=xml --cov-report=html \
            --durations=0 \
            --durations-min=0 -v --tb=short | tee pytest-smoke.log

      - name: Generate coverage JSON
        continue-on-error: true
        run: |
          cd /opt/proteus
          coverage json --fail-under=${FAST_COV_FAIL_UNDER} -o coverage-unit.json

      - name: Download last nightly coverage (for estimated total)
        if: always()
        continue-on-error: true  # Do not fail job when no nightly artifact exists yet
        uses: dawidd6/action-download-artifact@v3
        with:
          workflow: ci-nightly-science-v5.yml
          name: v5-branch-nightly-coverage
          path: nightly-coverage
          workflow_conclusion: success
          if_no_artifact_found: warn

      - name: Copy nightly integration coverage into container
        if: always()
        run: |
          if [ -f nightly-coverage/coverage-integration-only.json ]; then
            cp nightly-coverage/coverage-integration-only.json /opt/proteus/
          fi

      - name: Write workflow summary (visible on Actions run page)
        if: always()
        env:
          UNIT_OUTCOME: ${{ steps.unit-tests.outcome }}
          SMOKE_OUTCOME: ${{ steps.smoke-tests.outcome }}
        run: |
          cd /opt/proteus
          python - <<'PY'
          import json
          import os
          import pathlib

          def read_totals(path):
              try:
                  with open(path) as f:
                      data = json.load(f)
                  t = data.get("totals", {})
                  return t.get("percent_covered", 0), t.get("covered_lines", 0), t.get("num_statements", 0)
              except Exception:
                  return 0, 0, 0

          def norm_path(p):
              p = p.replace("\\", "/")
              if "proteus/" in p:
                  return "proteus/" + p.split("proteus/", 1)[-1]
              if "src/" in p:
                  return p.split("src/", 1)[-1]
              return p

          def line_set_from_files(data):
              """Set of (norm_path, line) for executed lines."""
              out = set()
              for path, fd in data.get("files", {}).items():
                  n = norm_path(path)
                  for line in fd.get("executed_lines", []) or []:
                      out.add((n, line))
              return out

          def executable_set_from_files(data):
              """Set of (norm_path, line) for executed | missing (all executable lines)."""
              out = set()
              for path, fd in data.get("files", {}).items():
                  n = norm_path(path)
                  for line in (fd.get("executed_lines", []) or []) + (fd.get("missing_lines", []) or []):
                      out.add((n, line))
              return out

          u_pct, u_covered, u_total = read_totals(pathlib.Path("coverage-unit.json"))
          u_data = {}
          try:
              if pathlib.Path("coverage-unit.json").exists():
                  u_data = json.loads(pathlib.Path("coverage-unit.json").read_text())
          except (json.JSONDecodeError, OSError):
              pass
          i_data = {}
          try:
              if pathlib.Path("coverage-integration-only.json").exists():
                  i_data = json.loads(pathlib.Path("coverage-integration-only.json").read_text())
          except (json.JSONDecodeError, OSError):
              pass
          i_pct, i_covered, i_total = read_totals(pathlib.Path("coverage-integration-only.json"))

          # Estimated total: (a) with overlap removed (union), (b) simple sum
          has_est = False
          est_pct_union = None
          est_covered_union = 0
          est_total_union = 0
          est_pct_sum = None
          est_covered_sum = 0
          est_total_sum = 0
          overlap_removed = False
          if u_data.get("files") and i_data.get("files"):
              u_exec = line_set_from_files(u_data)
              i_exec = line_set_from_files(i_data)
              u_all = executable_set_from_files(u_data)
              i_all = executable_set_from_files(i_data)
              union_covered = u_exec | i_exec
              union_executable = u_all | i_all
              if union_executable:
                  est_covered_union = len(union_covered)
                  est_total_union = len(union_executable)
                  est_pct_union = min(100.0, 100.0 * est_covered_union / est_total_union)
                  overlap_removed = True
          if u_total and u_total > 0:
              est_covered_sum = u_covered + i_covered
              est_total_sum = u_total
              est_pct_sum = min(100.0, 100.0 * est_covered_sum / u_total)
              has_est = True

          summary_path = pathlib.Path(os.environ.get("GITHUB_STEP_SUMMARY", "/tmp/summary.md"))
          unit_outcome = os.environ.get("UNIT_OUTCOME", "unknown")
          smoke_outcome = os.environ.get("SMOKE_OUTCOME", "unknown")
          with open(summary_path, "w") as f:
              f.write("# Fast PR Checks – Summary\n\n")
              f.write("## Which tests failed\n\n")
              f.write(f"- **Unit tests:** {unit_outcome}\n")
              f.write(f"- **Smoke tests:** {smoke_outcome}\n\n")
              f.write("## Total test coverage (unit + smoke tests, this run)\n\n")
              f.write(f"- **Line coverage:** **{u_pct:.2f}%**\n")
              f.write(f"- **Covered lines:** {u_covered} / {u_total}\n\n")
              f.write("## Integration coverage (last Nightly Science v5 run)\n\n")
              if i_total:
                  f.write(f"- **Line coverage:** **{i_pct:.2f}%**\n")
                  f.write(f"- **Covered lines:** {i_covered} / {i_total}\n\n")
              else:
                  f.write("- *No nightly artifact found; use **Nightly Science Validation (v5)** for integration numbers.*\n\n")
              if has_est:
                  f.write("## Estimated total (unit this PR + integration last nightly)\n\n")
                  if overlap_removed:
                      f.write(
                          f"- **With overlap removed (union):** **{est_pct_union:.2f}%** — {est_covered_union} / {est_total_union} lines\n"
                      )
                      f.write(
                          f"- **Without overlap removed (simple sum):** **{est_pct_sum:.2f}%** — {est_covered_sum} / {est_total_sum} lines\n\n"
                      )
                      f.write("- **Union formula:** covered (file, line) from unit ∪ integration, over union of executable lines.\n")
                      f.write("- **Simple-sum formula:** `(unit_covered + integration_covered) / unit_total`; double-counts overlap.\n\n")
                  else:
                      f.write(
                          f"- **Estimated line coverage:** **{est_pct_sum:.2f}%** — {est_covered_sum} / {est_total_sum} lines\n\n"
                      )
                      f.write("- **Formula:** `(unit_covered + integration_covered) / total_lines` (per-file data missing; overlap not removed).\n\n")
                  if not i_total:
                      f.write("- Integration from last nightly unavailable; estimated total uses unit coverage only.\n\n")
              else:
                  f.write("## Estimated total\n\n")
                  f.write("- Not computed (unit coverage data missing).\n\n")
              f.write("### Notes\n")
              f.write("- Coverage above is from **unit + smoke** tests (this run). Integration: last **Nightly Science Validation (v5)** run.\n")
              f.write("- Placeholder tests (`@pytest.mark.skip`) are excluded.\n")
              f.write("- See `docs/test_infrastructure.md` for testing strategy.\n")

          disp_est = f"{est_pct_union:.2f}% (union) / {est_pct_sum:.2f}% (sum)" if overlap_removed and has_est else (f"{est_pct_sum:.2f}%" if has_est else "—")
          print(f"Unit: {u_pct:.2f}% | Integration (last nightly): {i_pct:.2f}% | Estimated total: {disp_est}")
          PY

      - name: Diff coverage on changed lines (fast suite)
        id: diff-cover
        env:
          BASE_REF: ${{ github.event.pull_request.base.ref || 'main' }}
        run: |
          # Fetch base branch and generate diff file to avoid remote fetch issues in container
          cd /__w/PROTEUS/PROTEUS
          git config --global --add safe.directory /__w/PROTEUS/PROTEUS
          git fetch --no-tags --prune --depth=100 origin "${BASE_REF}"
          git diff "origin/${BASE_REF}...HEAD" > /tmp/pr-changes.diff

          # Run diff-cover using the prepared diff file
          diff-cover /opt/proteus/coverage.xml --diff-file /tmp/pr-changes.diff --fail-under=80

      - name: Append failure guidance (needs more unit tests)
        if: (failure() && !cancelled()) && (steps.unit-tests.outcome == 'failure' || steps.smoke-tests.outcome == 'failure' || steps.diff-cover.outcome == 'failure')
        run: |
          {
            echo ""
            echo "---"
            echo "## PR did not pass checks"
            echo ""
            echo "This run failed because **unit tests**, **smoke tests**, or **diff-cover on changed lines** did not pass. See the \"Which tests failed\" section above."
            echo ""
            echo "See **[How to create more unit tests](https://github.com/FormingWorlds/PROTEUS/blob/main/docs/test_building.md)** for guidance."
          } >> "$GITHUB_STEP_SUMMARY"

      - name: Fail job if unit or smoke tests failed
        if: always() && (steps.unit-tests.outcome == 'failure' || steps.smoke-tests.outcome == 'failure')
        run: exit 1

      - name: Ratchet fast coverage threshold
        continue-on-error: true
        run: |
          cd /opt/proteus
          python tools/update_coverage_threshold.py --coverage-file coverage-unit.json --target fast

      - name: Commit ratcheted threshold (if changed)
        if: github.event_name == 'push' && (github.ref == 'refs/heads/main' || github.ref == 'refs/heads/tl/test_ecosystem_v5')
        continue-on-error: true
        run: |
          cd /__w/PROTEUS/PROTEUS
          git config --global user.name "github-actions[bot]"
          git config --global user.email "github-actions[bot]@users.noreply.github.com"

          # Copy updated pyproject.toml from container to workspace
          cp /opt/proteus/pyproject.toml /__w/PROTEUS/PROTEUS/pyproject.toml

          # Check if there are changes
          if git diff --quiet pyproject.toml; then
            echo "No threshold changes to commit"
          else
            git add pyproject.toml
            COVERAGE=$(grep -A2 '\[tool.proteus.coverage_fast\]' pyproject.toml | grep 'fail_under' | awk '{print $3}')
            git commit -m "ratchet: Auto-update fast coverage threshold to ${COVERAGE}% [skip ci]"
            git push
            echo "✓ Committed ratcheted threshold: ${COVERAGE}%"
          fi

      - name: Install gpg for Codecov verification
        if: always()
        run: |
          apt-get update
          apt-get install -y gnupg

      - name: Upload coverage report
        uses: codecov/codecov-action@v4
        if: always()
        with:
          files: /opt/proteus/coverage.xml
          flags: unit-tests
          name: unit-tests-coverage
          fail_ci_if_error: false
        env:
          CODECOV_TOKEN: ${{ secrets.CODECOV_TOKEN }}

      - name: Upload HTML coverage
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: unit-coverage-html
          path: /opt/proteus/htmlcov/
          retention-days: 7

      - name: Upload unit pytest log
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: unit-pytest-log
          path: /opt/proteus/pytest-unit.log
          retention-days: 7

      - name: Upload smoke pytest log
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: smoke-pytest-log
          path: /opt/proteus/pytest-smoke.log
          retention-days: 7

      - name: Upload smoke test artifacts on failure
        uses: actions/upload-artifact@v4
        if: failure() && steps.smoke-tests.outcome == 'failure'
        with:
          name: smoke-test-failures
          path: |
            /opt/proteus/output/
            /opt/proteus/tests/**/*.log
          retention-days: 7

  lint:
    name: Code Quality (ruff)
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python 3.12
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install ruff
        run: pip install ruff

      - name: Run ruff check
        run: ruff check src/ tests/

      - name: Run ruff format check
        run: ruff format --check src/ tests/
