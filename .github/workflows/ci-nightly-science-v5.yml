name: CI - Nightly Science Validation (v5)

on:
  push:
    branches:
      - tl/test_ecosystem_v5
  workflow_dispatch:

permissions:
  contents: read
  packages: read

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: formingworlds/proteus

jobs:
  branch-nightly-coverage:
    name: Branch Nightly Coverage (Integration - v5)
    runs-on: ubuntu-latest
    timeout-minutes: 30
    container:
      image: ghcr.io/formingworlds/proteus:tl-test_ecosystem_v5
      credentials:
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}
      options: --user root

    steps:
      - name: Checkout branch code
        uses: actions/checkout@v4
        with:
          ref: tl/test_ecosystem_v5
          fetch-depth: 0

      - name: Overlay code onto container
        run: |
          echo "Copying code over container base..."
          rsync -av --exclude='SPIDER' --exclude='socrates' --exclude='petsc' --exclude='AGNI' . /opt/proteus/
          cd /opt/proteus
          git config --global --add safe.directory /opt/proteus
          # Set Julia depot to /opt where there's more disk space
          export JULIA_DEPOT_PATH=/opt/julia_depot
          mkdir -p /opt/julia_depot
          pip install -e ".[develop]" --no-deps

      - name: Read full coverage threshold
        run: |
          cd /opt/proteus
          python - <<'PY' >> "$GITHUB_ENV"
          import pathlib
          import tomllib

          data = tomllib.loads(pathlib.Path("pyproject.toml").read_text())
          val = float(data["tool"]["coverage"]["report"]["fail_under"])
          print(f"FULL_COV_FAIL_UNDER={val}")
          PY

      - name: Download test data
        run: |
          cd /opt/proteus
          # Download all required data based on all_options.toml configuration
          # This ensures all modules (MORS, ARAGOG, AGNI, etc.) have their required data
          python -c "
          import sys
          import os
          from pathlib import Path
          import traceback

          # Ensure MORS is available for stellar track downloads
          try:
              import mors
              print(f'MORS version: {mors.__version__ if hasattr(mors, \"__version__\") else \"unknown\"}')
          except ImportError as e:
              print(f'ERROR: MORS not available: {e}')
              print('Installing MORS...')
              import subprocess
              subprocess.run([sys.executable, '-m', 'pip', 'install', 'fwl-mors'], check=True)
              import mors
              print('MORS installed successfully')

          # Download data using download_sufficient_data
          try:
              from proteus.config import read_config_object
              from proteus.utils.data import download_sufficient_data
              config = read_config_object('input/all_options.toml')
              print('Downloading required data for all_options.toml...')
              download_sufficient_data(config, clean=False)
              print('Data download completed.')
          except Exception as e:
              print(f'ERROR during data download: {e}')
              traceback.print_exc()
              # Try to download critical data explicitly
              print('Attempting explicit data downloads...')

              # Try ARAGOG data
              try:
                  from proteus.utils.data import download_interior_lookuptables, download_melting_curves
                  print('Downloading ARAGOG lookup tables...')
                  download_interior_lookuptables(clean=False)
                  download_melting_curves(config, clean=False)
                  print('ARAGOG data download completed.')
              except Exception as e_aragog:
                  print(f'Warning: ARAGOG data download failed: {e_aragog}')

              # Try stellar tracks using MORS directly
              try:
                  print('Downloading stellar evolution tracks via MORS...')
                  from mors.data import DownloadEvolutionTracks
                  DownloadEvolutionTracks('Spada')
                  print('Stellar tracks download completed.')
              except Exception as e_stellar:
                  print(f'Warning: Stellar tracks download failed: {e_stellar}')
                  traceback.print_exc()

          # Verify critical data exists
          fwl_data = os.environ.get('FWL_DATA', '/opt/proteus/fwl_data')
          aragog_path = Path(fwl_data) / 'interior_lookup_tables/1TPa-dK09-elec-free/MgSiO3_Wolf_Bower_2018_1TPa'
          stellar_path = Path(fwl_data) / 'stellar_evolution_tracks/Spada'

          print(f'\\nVerifying data downloads...')
          print(f'FWL_DATA: {fwl_data}')

          if aragog_path.exists():
              print(f'✓ ARAGOG data found at {aragog_path}')
          else:
              print(f'✗ ARAGOG data NOT found at {aragog_path}')
              # List what's actually there
              parent = aragog_path.parent
              if parent.exists():
                  print(f'  Contents of {parent}:')
                  for item in list(parent.iterdir())[:5]:
                      print(f'    - {item.name}')

          if stellar_path.exists():
              print(f'✓ Stellar tracks found at {stellar_path}')
              # Check if specific track files exist
              track_files = list(stellar_path.rglob('*.track1'))
              if track_files:
                  print(f'  Found {len(track_files)} track files')
              else:
                  print(f'  Warning: No .track1 files found in {stellar_path}')
          else:
              print(f'✗ Stellar tracks NOT found at {stellar_path}')
              # Try one more time with MORS
              try:
                  print('Attempting final stellar tracks download...')
                  from mors.data import DownloadEvolutionTracks
                  DownloadEvolutionTracks('Spada')
                  if stellar_path.exists():
                      print('✓ Stellar tracks downloaded successfully')
                  else:
                      print('✗ Stellar tracks still not found after download attempt')
              except Exception as e:
                  print(f'✗ Final stellar tracks download failed: {e}')
          "

      - name: Free up disk space and configure Julia
        run: |
          # Use /opt for Julia depot instead of /tmp (more space in container)
          export JULIA_DEPOT_PATH=/opt/julia_depot
          mkdir -p /opt/julia_depot
          echo "JULIA_DEPOT_PATH=/opt/julia_depot" >> $GITHUB_ENV
          # Check available space in /opt
          df -h /opt

      - name: Run integration coverage (dummy + integration and not slow)
        continue-on-error: true  # Don't fail workflow if some integration tests fail
        run: |
          cd /opt/proteus
          coverage erase
          pytest tests/integration/test_integration_dummy.py \
            -v --tb=short \
            --cov=proteus \
            --cov-fail-under=0 \
            --cov-report=term-missing \
            --cov-report=xml:coverage.xml \
            --cov-report=html \
            --cov-config=pyproject.toml
          # Then full integration (excluding slow, AGNI, and albedo tests requiring external data)
          pytest tests/integration \
            -m "integration and not slow" \
            --ignore=tests/integration/test_integration_dummy_agni.py \
            --ignore=tests/integration/test_albedo_lookup.py \
            -v --tb=short \
            --cov=proteus \
            --cov-append \
            --cov-fail-under=0 \
            --cov-report=term-missing \
            --cov-report=xml:coverage.xml \
            --cov-report=html \
            --cov-config=pyproject.toml

      - name: Save integration-only coverage (for Fast PR estimated total)
        if: always()
        run: |
          cd /opt/proteus
          coverage json -o coverage-integration-only.json || echo '{"totals":{"percent_covered":0,"covered_lines":0,"num_statements":0}}' > coverage-integration-only.json

      - name: Run unit tests with coverage (append for total = unit + integration)
        continue-on-error: true
        run: |
          cd /opt/proteus
          pytest -m "unit and not skip" \
            --ignore=tests/examples \
            -v --tb=short \
            --cov=proteus \
            --cov-append \
            --cov-fail-under=0 \
            --cov-report=term-missing \
            --cov-report=xml:coverage.xml \
            --cov-report=html \
            --cov-config=pyproject.toml

      - name: Run slow integration tests (standard config)
        if: always()  # Run even if previous step failed
        continue-on-error: true  # Don't fail workflow if test fails
        run: |
          cd /opt/proteus
          # Run slow integration tests (standard config with all real modules)
          # These require ARAGOG lookup data and may take 10-15 minutes
          pytest tests/integration/test_integration_std_config.py \
            -m "slow" \
            -v --tb=long \
            --cov=proteus \
            --cov-append \
            --cov-fail-under=0 \
            --cov-report=term-missing \
            --cov-report=xml:coverage.xml \
            --cov-report=html \
            --cov-config=pyproject.toml

      - name: Generate coverage JSON
        run: |
          cd /opt/proteus
          coverage json -o coverage-branch-nightly.json || true

      - name: Write workflow summary (visible on Actions run page)
        if: always()
        run: |
          cd /opt/proteus
          python - <<'PY'
          import json
          import os
          import pathlib

          summary_path = pathlib.Path(os.environ.get("GITHUB_STEP_SUMMARY", "/tmp/summary.md"))
          with open(summary_path, "w") as f:
              f.write("# Nightly Science Validation (v5) – Summary\n\n")

          try:
              data = json.load(open("coverage-branch-nightly.json"))
              t = data.get("totals", {})
              pct = t.get("percent_covered", 0)
              covered = t.get("covered_lines", 0)
              total = t.get("num_statements", 0)
              with open(summary_path, "a") as f:
                  f.write("## Total test coverage (unit + integration)\n\n")
                  f.write(f"- **Line coverage:** **{pct:.2f}%**\n")
                  f.write(f"- **Covered lines:** {covered} / {total}\n\n")
                  f.write("Coverage includes unit tests, integration tests (dummy + integration), and slow integration tests.\n")
          except Exception as e:
              with open(summary_path, "a") as f:
                  f.write("## Total test coverage\n\n")
                  f.write(f"*Coverage report not available: {e}*\n")
          PY

      - name: Upload coverage XML and HTML
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: v5-branch-nightly-coverage
          path: |
            /opt/proteus/coverage.xml
            /opt/proteus/htmlcov/
            /opt/proteus/coverage-branch-nightly.json
            /opt/proteus/coverage-integration-only.json
          retention-days: 14
